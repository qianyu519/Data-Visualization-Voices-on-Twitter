<html>
<head>
	<title>Twitter Visualization</title>
	<script src="https://d3js.org/d3.v7.min.js"></script>
	<script src="https://unpkg.com/simple-statistics@7.7.0/dist/simple-statistics.min.js"></script>
	<script src="https://cdn.jsdelivr.net/gh/holtzy/D3-graph-gallery@master/LIB/d3.layout.cloud.js"></script>
	<script src="http://ajax.googleapis.com/ajax/libs/dojo/1.14.1/dojo/dojo.js" data-dojo-config="async: true"></script>
	<script src="require.js"></script>
	<script src="main_view.js"></script>
	<script src="topic_view.js"></script>
	<script src="detail_view.js"></script>
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
	<style>
		div.container {
			margin-top: 10px;
			margin-bottom: 10px;
			margin-right: 10px;
			margin-left: 10px;
			padding: 10px 10px 10px 10px;
			background-color: white;
		}

		.selected {
			stroke: yellow;
			stroke-width: 5px;
		}

		.shallow {
			stroke-opacity: 50%;
		}
		.text {
			font-family: sans-serif;
			font-size: 20px;
			font-style:italic;
			border: 2px solid Gainsboro;
			border-radius: 5px;
		}
		.interval{
			height: 30px;
		}
		.title {
			font-family: sans-serif;
			font-size: 20px;
			font-weight:    bold;
		}
	</style>
</head>
<body>

<!--
This span is used to show the title of this webpage.
-->
<img src="twitter-1.png", alt="Icon" width="100">
<span id="details" style="font-weight: bold">Voices on Twitter</span>

<!--
Container for main body of text of the webpage
-->
<div class="text-container">
	<h2 id="title" style="font-weight: bold">Overview</h1>
	<p>
		Social media platforms have become a prevalent way to share and gather information, especially in recent years. With the high volume of both users and data, social media platforms enable people to discover and learn first-hand knowledge and at lightning-fast pace.
		In many cases, people with different backgrounds and ideologies generate various content and perspectives regarding the same event, experience, or subject. This phenomenon, combined with the massive volume of the data, makes data analysis often difficult to readily interpret and analyze, 
		particularly when considering that a major portion of the data is highly heterogenuous. There is a clear gap between any type of social media researchers and the web-generated data, which is where this project will focus on. Using various analytical techniques,
		the purpose of this project was to develop a tool designed to summarize and compare the posts generated by different categories of users. 
	</p>

	<p>
		To create a visualization, this project chose Twitter as the social media platform to analyze. What makes Twitter interesting to analyze is the growing number of users, current prominence as social media, and the accessibility of the data through Twitter's 
		public API. The specific topic to analyze was the COVID-19 pandemic. For this topic, the tool aimed to design a visualization tool that is intuitive for users without domain knowledge in the interested field and easy to use for most web users. Specifically,
		this tool was designed to answer the following questions:
		<ol type="1">
			<li>What are the major sub-topics of interest for the overarching topic?</li>
			<li>How are these sub-topics related, if at all?</li>
			<li>How controversial are particular topics? What kinds of opinions are being shared about that topic?</li>
			<li>Are there any temporal changes in the topics?</li>
		</ol>
	</p>

	<h2>Data</h2>
	<p>
		As mentioned previously, the data was collected through Twitter's publicly available API. For the purpose of this project, 38 dates were randomly selected from March 2020 through September 2021. Relevant Tweets were selected by searching exclusively for
		Tweets containing at least one of the following hashtags and keywords:
		<ol type="1">
			<li>#COVID</li>
			<li>#covid</li>
			<li>covid</li>
		</ol>
		For each of these dates, to compensate for the extremely high volume, 170,000 Tweets were randomly selected. This was done to reduce the overall data volume to facilitate faster data analysis but maintain a representative sample for a given date. One advantage
		to using Twitter data is that almost every user's tweets are completely public and pullable, so for a given day, there is a safe assumption that most relevant Tweets were curated. In total, there were roughly 6.5 million Tweets collected. The average length
		of the Tweets was 230 characters. 29.6% of the sampled Tweets contained at least one mention (an "@"") at a specific user. 67.8% of the sampled Tweets contained at least one URL or external link. This project focused solely on the text data generated, so 
		this does mean that a high proportion of the Tweet data were not included in the analysis and, thus, the visualization. This would include any type of image or video data, as well as potential text data in external links. For COVID-19, this may include news articles 
		or research studies that users have shared. 
	</p>

	<h2>Design Methodology</h2>
	<p>
		After data collection, the text data was preprocessed and then analyzed. Topic modeling was performed with Latent Dirichlet Allocation (LDA) topic modeling, and it was determined than twelve topics was most accurate in order to reduce the incidence of redunancies
		but still maintain distinct topics. Each Tweet was assigned a list of likely topics with associated probabilities. The highest-likelihood singular topic was assigned to each Tweet for the sake of the visualization. Additionally, sentiment analysis was performed 
		using VADER, whichh is available through the natural language toolkit library (nltk) in Python. Each Tweet was predicted to have one of three labels: positive, neutral, and negative. Like topic modeling, each Tweet had an associated probability for each classification. 
		All of the Tweets for each topic had combined sentiment scores to derive an overall sentiment score for that topic on a given day.
	</p>
		
	<p>
		Likewise, LDA topic modeling was performed on the randomly sampled dataset. Each topic was interpreted using the derived keywords. To estimate distances between topics, <a href="https://github.com/cpsievert/LDAvis">LDAvis</a> was run on the generated model. 
		LDAvis is an existing topic modeling visualization, which was also the basis of the final visualization as well. The initial results are shown in the following figure.
	</p>

	<div class ="container">
		<img class="figure" src="prototype1.png" alt="Topic Modeling Visualization">
	</div>

	<p>
		After the initial data analysis and rudimentary visualizations, prototyping began by focusing on mediating two different components:
		<ol type="1">
			<li>Spatial representatation of the topic modeling</li>
			<li>Details of each selected topic</li>
		</ol>
		Important components to include with the topic view included the overall sentiment, related topics, and example Tweets. These were selected, as these would be the most readily useful and simple to interpret for any given user, regardless of domain expertise.
		With these key factors in mind, the following prototype was developed.
	</p>

	<div class="container">
		<img class="figure" src="prototype2.png" alt="Initial Prototyping">
	</div>

	<p>
		Essentially, Panel A describes each topic, which are represented with a bubble. The size is determined by the percentage of Tweets for that day belonging to that specific topic. The locations of the topics are encoded with semantic distance between them, and 
		the connections drawn between topics indicate topical connections in terms of keywords and Tweet overlap. This panel was deisnged to provide users a simple overview of the dominant topics, and how they fit to the larger topic of COVID-19. The bottom of the panel 
		contains a scroll bar, which enables users to adjust the date of focus. This functionality may help users understand how topics shift with time.
	</p>

	<p>
		In Panel B, there is a side panel that displays more details about each selected topic after a user clicks on a topic bubble. For instance, if a user were to select the "vaccine" topic in the prototype figure, the included keywords would be shown in a 
		word cloud format and bar chart. Below that, the dominant sentiment would be shown in the format of a pie chart. There would also be a miniature topic graph, so users would be able to easily see related topics without having to refer back to the main 
		topic visualization. And finally, the bottom component would include a list of example Tweets from that day for the topic. These elements would help users develop better understanding of the topic and decide which topic to focus on next.
	</p>

	<h2>Changes to Design</h2>
	<p>
		The most taxing and longest section of this project was actually data curation, data preprocessing, and initial text data analysis. Most of the project's lifecycle was spent towards the beginning stages. Social media data is inherently chaotic and voluminous, 
		so working with this sort of data and assessing meaningful conclusions prior to the visualization design was paramount to actually simplifying the visualization design. The final visualization prototyping was, in comparison, a much simpler and straight-forward 
		process. In that respect, the team decision to work carefully and precisely with the Twitter data before visualization design was a key factor in the eventual success of the visualization design. From the expected design, all of the major components were included 
		and fully functional in a satisfactory manner. Notably, the bar chart and the miniature topic connection models were excluded from the final design, as it was collectively decided that these would only introduce more noise to users and may distract from what 
		users may extract from the visualization itself. Of course, these could have simply been moved to other parts of the screen or included in some other manner, but the final design effectively communicates what was initially sought out for at the onset of this project.
		 Again, it must be stated that the primary driving force in few changes to the design plan was having a clear understanding of the data after preliminary analysis. 
	</p>

	<h2>Ethical and Societal Considerations</h2>
	<p>
		With the ongoing COVID-19 pandemic, there were certainly many decisions that had to be made carefully in the visualization design. It was paramount for the final prototype to reflect accurate and unbiased data. For this reason, it was imperative that 
		this project bring together a comprehrensive body of opinions, views, and interesting conclusions from the Twitter data so that any interested users would be able to understand relevant issues for COVID-19.
	</p>

</div>

<!--
This is the container in which D3 will draw the scatter plot.
-->
<div id="vis_container" style="width:100%;">
</div>

<!--
Finally, here comes the Javascript code.
-->
<script>
	// var mydata = JSON.parse(data);
	fetch("https://opal.ils.unc.edu/~mtguo/inls641_hw/agg.json")
			.then(res => res.json())
			.then((out) => {
					// Initialize the visualization
					let main_view = new Main_view("vis_container");
					main_view.init(out);
			}).catch(err => console.error(err));
	// d3.json("https://opal.ils.unc.edu/~mtguo/inls641_hw/agg.json", function(data) {
	// 	console.log(data);

	// });

</script>
</body>
</html>
